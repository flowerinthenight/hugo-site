














    
        
    

    
        
    

    
        
    

    
        
    







    

    






<?xml version="1.0" encoding="utf-8"?>
<feed  xml:lang="en"  xmlns="http://www.w3.org/2005/Atom">
    
        <author>
            
                <email>example@example.com</email>
            

            
                <name>John Doe</name>
            

            
                <uri>https://example.com</uri>
            
        </author>
    

    
        <icon>http://localhost:1313/</icon>
    

    <id>tag:localhost:1313,0001-01-01:/tags/port-forward/atom.xml</id>

    
        

        
            
        

        
            <link href="http://localhost:1313/tags/port-forward/atom.xml" rel="self" type="application/atom+xml"/>
        
    
        

        
            
        

        
            <link href="http://localhost:1313/tags/port-forward/" rel="alternate" type="text/html"/>
        
    
        

        

        
            <link href="http://localhost:1313/tags/port-forward/rss.xml" rel="alternate" type="application/rss+xml"/>
        
    

    

    
        <logo>http://localhost:1313/</logo>
    

    
        <rights type="html"><![CDATA[© Flowerinthenight, 2016-2024. All rights reserved.]]></rights>
    

    

    <title type="html"><![CDATA[Port-Forward · Tags · About]]></title>
    <updated>2024-01-18T21:32:52-07:00</updated>

    
        <entry>
            
            
            
            
            
            
            

            

            

            

            

            
                
            

            

            
                <content type="html"><![CDATA[<p>Updated 2020/01/27:</p>
<ul>
<li>Support for forwarding to deployments and services</li>
</ul>
<p>Original post:</p>
<p>I recently uploaded a tool to GitHub that wraps <code>kubectl port-forward</code> command and supports port-forwarding to multiple pods. It&rsquo;s called <a href="https://github.com/flowerinthenight/kubepfm"><code>kubepfm</code></a>. I use this tool heavily in my development work. You can check out the code <a href="https://github.com/flowerinthenight/kubepfm">here</a>. You might find this useful.</p>
]]></content>
            

            <id>tag:localhost:1313,0001-01-01:/blog/2020-01-27-kubepfm-update/</id>

            
                

                
                    

                    <link href="http://localhost:1313/blog/2020-01-27-kubepfm-update/" rel="alternate" type="text/html"/>
                
            

            

            

            
                <rights type="html"><![CDATA[© Flowerinthenight, 2016-2024. All rights reserved.]]></rights>
            

            

            <title type="html"><![CDATA[Update to kubepfm, a kubectl port-forward wrapper for multiple pods]]></title>
            <updated>0001-01-01T00:00:00Z</updated>
        </entry>
    
        <entry>
            
            
            
            
            
            
            

            

            

            

            

            
                
            

            

            
                <content type="html"><![CDATA[<p>Updated 2019/02/20:</p>
<ul>
<li>Support for namespaces <a href="https://github.com/flowerinthenight/kubepfm/issues/1">https://github.com/flowerinthenight/kubepfm/issues/1</a></li>
<li>Improved handling of input patterns</li>
</ul>
<p>Original post:</p>
<p>I recently uploaded a tool to GitHub that wraps <code>kubectl port-forward</code> command and supports port-forwarding to multiple pods. It&rsquo;s called <a href="https://github.com/flowerinthenight/kubepfm"><code>kubepfm</code></a>. I use this tool heavily in my development work. You can check out the code <a href="https://github.com/flowerinthenight/kubepfm">here</a>. You might find this useful.</p>
]]></content>
            

            <id>tag:localhost:1313,0001-01-01:/blog/2019-02-20-kubepfm-update/</id>

            
                

                
                    

                    <link href="http://localhost:1313/blog/2019-02-20-kubepfm-update/" rel="alternate" type="text/html"/>
                
            

            

            

            
                <rights type="html"><![CDATA[© Flowerinthenight, 2016-2024. All rights reserved.]]></rights>
            

            

            <title type="html"><![CDATA[Update to kubepfm, a kubectl port-forward wrapper for multiple pods]]></title>
            <updated>0001-01-01T00:00:00Z</updated>
        </entry>
    
        <entry>
            
            
            
            
            
            
            

            

            

            

            

            
                
            

            

            
                <content type="html"><![CDATA[<p>I recently uploaded a tool to GitHub that wraps <code>kubectl port-forward</code> command and supports port-forwarding to multiple pods. It&rsquo;s called <a href="https://github.com/flowerinthenight/kubepfm"><code>kubepfm</code></a>. I use this tool heavily in my development work. You can check out the code <a href="https://github.com/flowerinthenight/kubepfm">here</a>. You might find this useful.</p>
]]></content>
            

            <id>tag:localhost:1313,0001-01-01:/blog/2018-07-24-kubepfm/</id>

            
                

                
                    

                    <link href="http://localhost:1313/blog/2018-07-24-kubepfm/" rel="alternate" type="text/html"/>
                
            

            

            

            
                <rights type="html"><![CDATA[© Flowerinthenight, 2016-2024. All rights reserved.]]></rights>
            

            

            <title type="html"><![CDATA[kubepfm, a kubectl port-forward wrapper for multiple pods]]></title>
            <updated>0001-01-01T00:00:00Z</updated>
        </entry>
    
        <entry>
            
            
            
            
            
            
            

            

            

            

            

            
                
            

            

            
                <content type="html"><![CDATA[<p>At <a href="https://mobingi.com">Mobingi</a>, when we are developing services that run on Kubernetes, we generally use <a href="https://github.com/kubernetes/minikube">Minikube</a> or <a href="https://blog.docker.com/2018/01/docker-mac-kubernetes/">Kubernetes in Docker for Mac</a>. We also have a cluster that runs on <a href="https://cloud.google.com/kubernetes-engine/">GKE</a> that we use for development. In this post, I will share how we access some of the services that are running on our development cluster.</p>
<h2 id="using-kubectl-port-forward">Using kubectl port-forward</h2>
<p>Using <a href="https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/">kubectl port-forward</a> is probably the cheapest and the most straightforward. For example, if I want to access a cluster service <code>svc1</code> through my localhost, I use <code>kubectl port-forward</code> like this:</p>
<p>{% highlight shell %}
$ kubectl get pod
NAME                            READY     STATUS    RESTARTS   AGE
svc1-66dd787767-d6b22           2/2       Running   0          7d
svc1-66dd787767-ks92f           2/2       Running   0          7d
svc2-578786c554-rlw2w           2/2       Running   0          7d</p>
<h1 id="this-will-connect-to-the-first-pod-we-have-two-available">This will connect to the first pod (we have two available):</h1>
<p>$ kubectl port-forward <code>kubectl get pod --no-headers=true -o \ custom-columns=:metadata.name | grep svc1 | head -n1</code> 8080:8080
Forwarding from 127.0.0.1:8080 -&gt; 8080
{% endhighlight %}</p>
<p>The left <code>8080</code> is my local port, the right <code>8080</code> is the pod port where svc1 is running.</p>
<p>One thing to note with <code>kubectl port-forward</code> through is that it won&rsquo;t disconnect automatically even when the pod is restarted, say for example, due to an update from CI. I have to restart the command by doing a Ctrl+C and then rerun.</p>
<h2 id="exposing-the-service-using-nodeport-or-loadbalancer">Exposing the service using NodePort or LoadBalancer</h2>
<p>This part is probably the easiest to setup. You can check the details from the Kubernetes <a href="https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types">documentation</a>. But you have to be careful though, especially with load balancers. These are not cheap. We have gone with this route during our early Kubernetes days and we ended up with a lot of load balancers. This was when our clusters were still in AWS. In AWS, (I&rsquo;m not sure if it is still the case now) when you specify <code>LoadBalancer</code> as service type, a classic load balancer will be provisioned for your service. That means one load balancer per exposed service!</p>
<p>When we moved to GKE, we started using <a href="https://github.com/kubernetes/ingress-gce">GLBC</a> which uses an L7 load balancer via the Ingress API. This improved our costs a little bit since GLBC can support up to five backend services per load balancer using paths. The slight downside was that Ingress updates were a bit slow. It&rsquo;s not a big deal though since it&rsquo;s only in the development cluster and we use blue/green deployment in production. But still, some updates can take up to ten minutes.</p>
<h2 id="using-nginx-as-a-reverse-proxy-to-cluster-services">Using nginx as a reverse proxy to cluster services</h2>
<p>In our quest to further minimize costs, we are currently using <a href="https://www.nginx.com/">nginx</a> as our way of exposing services. We provisioned a single Ingress that points to an nginx service which serves as a reverse proxy to our cluster services. This was the cheapest for us as we only have one load balancer for all services. And updating the nginx reverse proxy service takes only a few seconds. So far, this worked for us with no significant problems for the past couple of months.</p>
<p>Here&rsquo;s an example of an nginx reverse proxy service:</p>
<p>{% highlight ruby %}
apiVersion: v1
kind: ConfigMap
metadata:
name: serviceproxy-conf
data:
serviceproxy.conf: |
server {
listen 80;
server_name development.mobingi.com;
resolver kube-dns.kube-system.svc.cluster.local valid=10s;</p>
<pre><code>    location ~ ^/svc1/(.*)$ {
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $remote_addr;
        proxy_set_header Host $host;
        rewrite ^/svc1/(.*)$ /$1 break;
        proxy_pass &quot;http://svc1.default.svc.cluster.local&quot;;
        proxy_http_version 1.1;
    }

    location ~ ^/svc2/(.*)$ {
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $remote_addr;
        proxy_set_header Host $host;
        rewrite ^/svc2/(.*)$ /$1 break;
        proxy_pass &quot;http://svc2.default.svc.cluster.local&quot;;
        proxy_http_version 1.1;
    }

    # root health check requirement in GKE ingress
    location / {
        return 200 'healthy\n';
    }
}
</code></pre>
<hr>
<p>apiVersion: apps/v1
kind: Deployment
metadata:
name: serviceproxy
spec:
replicas: 1
revisionHistoryLimit: 3
selector:
matchLabels:
app: serviceproxy
template:
metadata:
labels:
app: serviceproxy
spec:
containers:
- name: nginx
image: nginx:1.13
ports:
- containerPort: 80
volumeMounts:
- name: config-volume
mountPath: /etc/nginx/conf.d/
volumes:
- name: config-volume
configMap:
name: serviceproxy-conf
items:
- key: serviceproxy.conf
path: serviceproxy.conf</p>
<hr>
<p>apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
name: serviceproxy-hpa
namespace: default
spec:
scaleTargetRef:
apiVersion: apps/v1
kind: Deployment
name: serviceproxy
minReplicas: 1
maxReplicas: 10
targetCPUUtilizationPercentage: 80</p>
<hr>
<p>apiVersion: v1
kind: Service
metadata:
name: serviceproxy
spec:
type: NodePort
ports:</p>
<ul>
<li>name: http
protocol: TCP
port: 80
targetPort: 80
selector:
app: serviceproxy
{% endhighlight %}</li>
</ul>
<p>In this example, all services, mainly <code>svc1</code> and <code>svc2</code>, are running in the <code>default</code> namespace. Save this as service.yaml and deploy:</p>
<p>{% highlight shell %}
$ kubectl create -f service.yaml
{% endhighlight %}</p>
<p>A sample Ingress controller for the reverse proxy service:</p>
<p>{% highlight ruby %}
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
name: serviceproxy-ingress
annotations:
kubernetes.io/ingress.class: &ldquo;gce&rdquo;
spec:
tls:</p>
<ul>
<li>secretName: mobingi-tls
rules:</li>
<li>host: development.mobingi.com
http:
paths:
<ul>
<li>backend:
serviceName: serviceproxy
servicePort: 80
{% endhighlight %}</li>
</ul>
</li>
</ul>
<p>Save this as ingress.yaml and deploy:</p>
<p>{% highlight shell %}
$ kubectl create -f ingress.yaml
{% endhighlight %}</p>
<p>After everything is ready (Ingress provisioning takes some time), you should be able to access <code>svc1</code> through <code>https://development.mobingi.com/svc1/some-endpoint</code>, <code>svc2</code> through <code>https://development.mobingi.com/svc2/another-endpoint</code>, etc. Of course, you have to point your domain to your Ingress load balancer&rsquo;s IP address which you can see using the following command:</p>
<p>{% highlight shell %}
$ kubectl get ingress serviceproxy-ingress
NAME                   HOSTS                     ADDRESS          PORTS     AGE
serviceproxy-ingress   development.mobingi.com   1.2.3.4          80, 443   91d
{% endhighlight %}</p>
<p>If you&rsquo;re wondering how to setup the TLS portion, you can refer to my previous <a href="https://flowerinthenight.com/blog/2018/02/20/k8s-tls-digicert">post</a> about the very subject.</p>
]]></content>
            

            <id>tag:localhost:1313,0001-01-01:/blog/2018-03-31-access-pods-k8s/</id>

            
                

                
                    

                    <link href="http://localhost:1313/blog/2018-03-31-access-pods-k8s/" rel="alternate" type="text/html"/>
                
            

            

            

            
                <rights type="html"><![CDATA[© Flowerinthenight, 2016-2024. All rights reserved.]]></rights>
            

            

            <title type="html"><![CDATA[Accessing services in Kubernetes]]></title>
            <updated>0001-01-01T00:00:00Z</updated>
        </entry>
    
</feed>
